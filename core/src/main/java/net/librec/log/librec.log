Dataset: ...ar/www/librec/data/filmtrust/rating
All dataset files [/var/www/librec/data/filmtrust/rating/ratings_3.txt, /var/www/librec/data/filmtrust/rating/ratings_1.txt, /var/www/librec/data/filmtrust/rating/ratings_2.txt, /var/www/librec/data/filmtrust/rating/ratings_0.txt]
All dataset files size 376445
Now loading dataset file ratings_3
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_0
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28378
Data size of testing is 7116
Job Setup completed.
NMFRecommender iter 0: loss = 7188.299266376958, delta_loss = -7188.2993
NMFRecommender iter 1: loss = 6761.195236676111, delta_loss = 427.10403
NMFRecommender iter 2: loss = 6457.7792310922305, delta_loss = 303.41602
NMFRecommender iter 3: loss = 6190.634846421058, delta_loss = 267.14438
NMFRecommender iter 4: loss = 5947.585502179479, delta_loss = 243.04935
NMFRecommender iter 5: loss = 5722.888913609527, delta_loss = 224.6966
NMFRecommender iter 6: loss = 5512.837617039922, delta_loss = 210.0513
NMFRecommender iter 7: loss = 5314.886032407006, delta_loss = 197.95158
NMFRecommender iter 8: loss = 5127.300326974849, delta_loss = 187.58571
NMFRecommender iter 9: loss = 4948.760749708483, delta_loss = 178.53958
NMFRecommender iter 10: loss = 4778.084201954873, delta_loss = 170.67654
Job Train completed.
Job End.
Job Setup completed.
PMFRecommender iter 1: loss = 132429.96702243199, delta_loss = -132429.97
PMFRecommender iter 2: loss = 78921.34684829824, delta_loss = 53508.62
PMFRecommender iter 3: loss = 46767.750019639585, delta_loss = 32153.598
PMFRecommender iter 4: loss = 39234.7414870325, delta_loss = 7533.0083
PMFRecommender iter 5: loss = 34531.6318785551, delta_loss = 4703.1094
PMFRecommender iter 6: loss = 31088.80438503538, delta_loss = 3442.8274
PMFRecommender iter 7: loss = 28455.379427300413, delta_loss = 2633.425
PMFRecommender iter 8: loss = 26413.42266026184, delta_loss = 2041.9568
PMFRecommender iter 9: loss = 24813.821726043716, delta_loss = 1599.601
PMFRecommender iter 10: loss = 23541.123895666093, delta_loss = 1272.6979
Job Train completed.
Job End.
Dataset: ...ar/www/librec/data/filmtrust/rating
All dataset files [/var/www/librec/data/filmtrust/rating/ratings_3.txt, /var/www/librec/data/filmtrust/rating/ratings_1.txt, /var/www/librec/data/filmtrust/rating/ratings_2.txt, /var/www/librec/data/filmtrust/rating/ratings_0.txt]
All dataset files size 376445
Now loading dataset file ratings_3
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_0
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28358
Data size of testing is 7136
Job Setup completed.
NMFRecommender iter 0: loss = 7132.428879944365, delta_loss = -7132.4287
NMFRecommender iter 1: loss = 6700.978530683908, delta_loss = 431.45035
NMFRecommender iter 2: loss = 6390.8165813469395, delta_loss = 310.16196
NMFRecommender iter 3: loss = 6118.797295428742, delta_loss = 272.0193
NMFRecommender iter 4: loss = 5872.36679934265, delta_loss = 246.4305
NMFRecommender iter 5: loss = 5645.266761266573, delta_loss = 227.10004
NMFRecommender iter 6: loss = 5433.490504739746, delta_loss = 211.77626
NMFRecommender iter 7: loss = 5234.239332259096, delta_loss = 199.25117
NMFRecommender iter 8: loss = 5045.466037382425, delta_loss = 188.7733
NMFRecommender iter 9: loss = 4865.627507782314, delta_loss = 179.83853
NMFRecommender iter 10: loss = 4693.535614306342, delta_loss = 172.09189
Job Train completed.
Job End.
Job Setup completed.
PMFRecommender iter 1: loss = 133362.87103344078, delta_loss = -133362.88
PMFRecommender iter 2: loss = 78349.3379306417, delta_loss = 55013.53
PMFRecommender iter 3: loss = 45120.528803192574, delta_loss = 33228.81
PMFRecommender iter 4: loss = 37900.06708882652, delta_loss = 7220.462
PMFRecommender iter 5: loss = 33259.30060257127, delta_loss = 4640.7666
PMFRecommender iter 6: loss = 29770.763306078614, delta_loss = 3488.5374
PMFRecommender iter 7: loss = 27063.408309421884, delta_loss = 2707.355
PMFRecommender iter 8: loss = 24947.6099865627, delta_loss = 2115.7983
PMFRecommender iter 9: loss = 23279.80593567907, delta_loss = 1667.8041
PMFRecommender iter 10: loss = 21946.169629431923, delta_loss = 1333.6364
PMFRecommender iter 11: loss = 20863.787571262452, delta_loss = 1082.3821
PMFRecommender iter 12: loss = 19973.58850674957, delta_loss = 890.19904
PMFRecommender iter 13: loss = 19232.72876497522, delta_loss = 740.85974
PMFRecommender iter 14: loss = 18609.599008273894, delta_loss = 623.12976
PMFRecommender iter 15: loss = 18080.55069072089, delta_loss = 529.04834
PMFRecommender iter 16: loss = 17627.59910968602, delta_loss = 452.95157
PMFRecommender iter 17: loss = 17236.811536174253, delta_loss = 390.78757
PMFRecommender iter 18: loss = 16897.199555711264, delta_loss = 339.61197
PMFRecommender iter 19: loss = 16599.965623617234, delta_loss = 297.23392
PMFRecommender iter 20: loss = 16337.9880027332, delta_loss = 261.97763
PMFRecommender iter 21: loss = 16105.461784319494, delta_loss = 232.52621
PMFRecommender iter 22: loss = 15897.64011525439, delta_loss = 207.82167
PMFRecommender iter 23: loss = 15710.639061442524, delta_loss = 187.00105
PMFRecommender iter 24: loss = 15541.283362838061, delta_loss = 169.3557
PMFRecommender iter 25: loss = 15386.979857203094, delta_loss = 154.30351
PMFRecommender iter 26: loss = 15245.611392633287, delta_loss = 141.36847
PMFRecommender iter 27: loss = 15115.447448532013, delta_loss = 130.16394
PMFRecommender iter 28: loss = 14995.069308693981, delta_loss = 120.37814
PMFRecommender iter 29: loss = 14883.308227250682, delta_loss = 111.76108
PMFRecommender iter 30: loss = 14779.19513070771, delta_loss = 104.1131
PMFRecommender iter 31: loss = 14681.92033089814, delta_loss = 97.2748
PMFRecommender iter 32: loss = 14590.801659190865, delta_loss = 91.118675
PMFRecommender iter 33: loss = 14505.259451832508, delta_loss = 85.542206
PMFRecommender iter 34: loss = 14424.79693950863, delta_loss = 80.46251
PMFRecommender iter 35: loss = 14348.98480099896, delta_loss = 75.81214
PMFRecommender iter 36: loss = 14277.448889836995, delta_loss = 71.53591
PMFRecommender iter 37: loss = 14209.860389748485, delta_loss = 67.5885
PMFRecommender iter 38: loss = 14145.927865458112, delta_loss = 63.932526
PMFRecommender iter 39: loss = 14085.390833583531, delta_loss = 60.537033
PMFRecommender iter 40: loss = 14028.014583285674, delta_loss = 57.37625
PMFRecommender iter 41: loss = 13973.586038594629, delta_loss = 54.428543
PMFRecommender iter 42: loss = 13921.910488429681, delta_loss = 51.67555
PMFRecommender iter 43: loss = 13872.809029843434, delta_loss = 49.10146
PMFRecommender iter 44: loss = 13826.116584576555, delta_loss = 46.692444
PMFRecommender iter 45: loss = 13781.680363795687, delta_loss = 44.436222
PMFRecommender iter 46: loss = 13739.358672478927, delta_loss = 42.32169
PMFRecommender iter 47: loss = 13699.01996284391, delta_loss = 40.33871
PMFRecommender iter 48: loss = 13660.542064149431, delta_loss = 38.477898
PMFRecommender iter 49: loss = 13623.811532890315, delta_loss = 36.73053
PMFRecommender iter 50: loss = 13588.723081990089, delta_loss = 35.08845
PMFRecommender iter 51: loss = 13555.179059791395, delta_loss = 33.54402
PMFRecommender iter 52: loss = 13523.088959372724, delta_loss = 32.0901
PMFRecommender iter 53: loss = 13492.368946262979, delta_loss = 30.720013
PMFRecommender iter 54: loss = 13462.941398276931, delta_loss = 29.427547
PMFRecommender iter 55: loss = 13434.73445521712, delta_loss = 28.206944
PMFRecommender iter 56: loss = 13407.681578956743, delta_loss = 27.052876
PMFRecommender iter 57: loss = 13381.721126097153, delta_loss = 25.960453
PMFRecommender iter 58: loss = 13356.795936281429, delta_loss = 24.92519
PMFRecommender iter 59: loss = 13332.85293950049, delta_loss = 23.942997
PMFRecommender iter 60: loss = 13309.84278550203, delta_loss = 23.010155
PMFRecommender iter 61: loss = 13287.71949795271, delta_loss = 22.123287
PMFRecommender iter 62: loss = 13266.440155243778, delta_loss = 21.279343
PMFRecommender iter 63: loss = 13245.964599110463, delta_loss = 20.475555
PMFRecommender iter 64: loss = 13226.25517139998, delta_loss = 19.709427
PMFRecommender iter 65: loss = 13207.276478615664, delta_loss = 18.978693
PMFRecommender iter 66: loss = 13188.995183194007, delta_loss = 18.281296
PMFRecommender iter 67: loss = 13171.37981995697, delta_loss = 17.615364
PMFRecommender iter 68: loss = 13154.400635773529, delta_loss = 16.979185
PMFRecommender iter 69: loss = 13138.029450187534, delta_loss = 16.371185
PMFRecommender iter 70: loss = 13122.239534632039, delta_loss = 15.789915
Job Train completed.
Job End.
Dataset: ...ar/www/librec/data/filmtrust/rating
All dataset files [/var/www/librec/data/filmtrust/rating/ratings_3.txt, /var/www/librec/data/filmtrust/rating/ratings_1.txt, /var/www/librec/data/filmtrust/rating/ratings_2.txt, /var/www/librec/data/filmtrust/rating/ratings_0.txt]
All dataset files size 376445
Now loading dataset file ratings_3
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_0
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28312
Data size of testing is 7182
Job Setup completed.
NMFRecommender iter 0: loss = 7138.2913720367405, delta_loss = -7138.2915
NMFRecommender iter 1: loss = 6707.3246542899315, delta_loss = 430.9667
NMFRecommender iter 2: loss = 6399.303865068545, delta_loss = 308.02078
NMFRecommender iter 3: loss = 6128.598744267106, delta_loss = 270.7051
NMFRecommender iter 4: loss = 5882.960977577454, delta_loss = 245.63777
NMFRecommender iter 5: loss = 5656.32750907249, delta_loss = 226.63347
NMFRecommender iter 6: loss = 5444.755945907132, delta_loss = 211.57156
NMFRecommender iter 7: loss = 5245.50037582861, delta_loss = 199.25557
NMFRecommender iter 8: loss = 5056.571719743715, delta_loss = 188.92865
NMFRecommender iter 9: loss = 4876.4808985164345, delta_loss = 180.09082
NMFRecommender iter 10: loss = 4704.086178146504, delta_loss = 172.39471
Job Train completed.
Job End.
Job Setup completed.
PMFRecommender iter 1: loss = 130107.24094684789, delta_loss = -130107.24
PMFRecommender iter 2: loss = 72571.77536087424, delta_loss = 57535.465
PMFRecommender iter 3: loss = 44180.72924249588, delta_loss = 28391.047
PMFRecommender iter 4: loss = 37351.95006793967, delta_loss = 6828.7793
PMFRecommender iter 5: loss = 32848.26129998786, delta_loss = 4503.689
PMFRecommender iter 6: loss = 29435.873631854367, delta_loss = 3412.3877
PMFRecommender iter 7: loss = 26792.114989743368, delta_loss = 2643.7585
PMFRecommender iter 8: loss = 24729.366521260887, delta_loss = 2062.7485
PMFRecommender iter 9: loss = 23098.798805476603, delta_loss = 1630.5677
PMFRecommender iter 10: loss = 21789.963098353524, delta_loss = 1308.8357
PMFRecommender iter 11: loss = 20725.180476185862, delta_loss = 1064.7826
PMFRecommender iter 12: loss = 19848.705294295665, delta_loss = 876.47516
PMFRecommender iter 13: loss = 19119.366900854242, delta_loss = 729.3384
PMFRecommender iter 14: loss = 18506.327241568506, delta_loss = 613.0397
PMFRecommender iter 15: loss = 17986.256549910824, delta_loss = 520.0707
PMFRecommender iter 16: loss = 17541.278494537106, delta_loss = 444.97806
PMFRecommender iter 17: loss = 17157.488083199616, delta_loss = 383.7904
PMFRecommender iter 18: loss = 16823.91023120484, delta_loss = 333.57785
PMFRecommender iter 19: loss = 16531.77554435302, delta_loss = 292.13467
PMFRecommender iter 20: loss = 16274.012336226233, delta_loss = 257.7632
PMFRecommender iter 21: loss = 16044.88250183713, delta_loss = 229.12984
PMFRecommender iter 22: loss = 15839.713279655867, delta_loss = 205.16922
PMFRecommender iter 23: loss = 15654.694078783325, delta_loss = 185.0192
PMFRecommender iter 24: loss = 15486.718428696118, delta_loss = 167.97565
PMFRecommender iter 25: loss = 15333.257794380423, delta_loss = 153.46063
PMFRecommender iter 26: loss = 15192.25825752624, delta_loss = 140.99954
PMFRecommender iter 27: loss = 15062.05401585031, delta_loss = 130.20424
PMFRecommender iter 28: loss = 14941.29385328414, delta_loss = 120.76016
PMFRecommender iter 29: loss = 14828.878369821516, delta_loss = 112.41548
PMFRecommender iter 30: loss = 14723.906846305077, delta_loss = 104.97153
PMFRecommender iter 31: loss = 14625.633160512958, delta_loss = 98.27369
PMFRecommender iter 32: loss = 14533.430251432139, delta_loss = 92.20291
PMFRecommender iter 33: loss = 14446.762422415122, delta_loss = 86.66783
PMFRecommender iter 34: loss = 14365.164485657568, delta_loss = 81.59794
PMFRecommender iter 35: loss = 14288.2265416018, delta_loss = 76.93794
PMFRecommender iter 36: loss = 14215.58313284614, delta_loss = 72.64341
PMFRecommender iter 37: loss = 14146.905606634442, delta_loss = 68.67753
PMFRecommender iter 38: loss = 14081.896710313898, delta_loss = 65.008896
PMFRecommender iter 39: loss = 14020.286669087061, delta_loss = 61.610043
PMFRecommender iter 40: loss = 13961.830208867712, delta_loss = 58.45646
PMFRecommender iter 41: loss = 13906.304164267947, delta_loss = 55.526043
PMFRecommender iter 42: loss = 13853.505445617295, delta_loss = 52.798717
PMFRecommender iter 43: loss = 13803.249232500559, delta_loss = 50.256214
PMFRecommender iter 44: loss = 13755.367322287457, delta_loss = 47.88191
PMFRecommender iter 45: loss = 13709.70659898465, delta_loss = 45.660725
PMFRecommender iter 46: loss = 13666.127608010493, delta_loss = 43.57899
PMFRecommender iter 47: loss = 13624.503232045667, delta_loss = 41.624374
PMFRecommender iter 48: loss = 13584.717466506228, delta_loss = 39.785767
PMFRecommender iter 49: loss = 13546.664293291844, delta_loss = 38.053173
PMFRecommender iter 50: loss = 13510.246650291609, delta_loss = 36.417645
PMFRecommender iter 51: loss = 13475.375492765903, delta_loss = 34.87116
PMFRecommender iter 52: loss = 13441.968941693238, delta_loss = 33.40655
PMFRecommender iter 53: loss = 13409.951513609145, delta_loss = 32.01743
PMFRecommender iter 54: loss = 13379.253426398516, delta_loss = 30.698088
PMFRecommender iter 55: loss = 13349.809975686952, delta_loss = 29.44345
PMFRecommender iter 56: loss = 13321.560976822362, delta_loss = 28.248999
PMFRecommender iter 57: loss = 13294.450267807122, delta_loss = 27.110708
PMFRecommender iter 58: loss = 13268.425268812565, delta_loss = 26.025
PMFRecommender iter 59: loss = 13243.436594106532, delta_loss = 24.988674
PMFRecommender iter 60: loss = 13219.437712307476, delta_loss = 23.998882
PMFRecommender iter 61: loss = 13196.384650916923, delta_loss = 23.05306
PMFRecommender iter 62: loss = 13174.235741075714, delta_loss = 22.14891
PMFRecommender iter 63: loss = 13152.951398514346, delta_loss = 21.284342
PMFRecommender iter 64: loss = 13132.493936727473, delta_loss = 20.457462
PMFRecommender iter 65: loss = 13112.827408515672, delta_loss = 19.666529
PMFRecommender iter 66: loss = 13093.917472201958, delta_loss = 18.909937
PMFRecommender iter 67: loss = 13075.731279068063, delta_loss = 18.186193
PMFRecommender iter 68: loss = 13058.237378807891, delta_loss = 17.4939
PMFRecommender iter 69: loss = 13041.40564008911, delta_loss = 16.83174
PMFRecommender iter 70: loss = 13025.207183612492, delta_loss = 16.198456
Job Train completed.
Job End.
